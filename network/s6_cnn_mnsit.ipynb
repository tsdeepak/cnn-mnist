{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsdeepak/cnn-mnist/blob/main/s6_cnn_mnsit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " !pip install --upgrade torch torchvision torchinfo tqdm matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAvp151EVyqL",
        "outputId": "1f206c9e-94e2-4708-8fa8-6e836e3f0585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchinfo import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "gROpo3TGV_RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "batch_size = 64\n",
        "\n",
        "kwargs = {'num_workers': 3, 'pin_memory': True} if device != 'cpu' else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=False, **kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCFrgOgkWJZo",
        "outputId": "02dd80f4-b979-443e-a954-e5be70689b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 91542581.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 36311658.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25124667.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3062293.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "\n",
        "DROP = 0.05\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.cnv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, padding=1, bias=False),    # Input -  28x28x1, Output -  28x28x8, RF - 3x3\n",
        "            nn.Dropout(DROP),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.Conv2d(8, 8, 3, padding=1, bias=False),    # Input -  28x28x8, Output -  28x28x8, RF - 5x5\n",
        "            nn.Dropout(DROP),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.t_block1 = nn.Sequential(\n",
        "            nn.MaxPool2d(2, 2)                            # Input -  28x28x8, Output -  14x14x8, RF - 6x6\n",
        "        )\n",
        "\n",
        "        self.cnv_block2 = nn.Sequential(\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.Conv2d(8, 16, 3, padding=1, bias=False),   # Input -  14x14x8, Output - 14x14x16, RF - 10x10\n",
        "            nn.Dropout(DROP),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 16, 3, padding=1, bias=False),  # Input - 14x14x16, Output - 14x14x16, RF - 14x14\n",
        "            nn.Dropout(DROP),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.t_block2 = nn.Sequential(\n",
        "            nn.MaxPool2d(2, 2)                            # Input - 14x14x16, Output -   7x7x16, RF - 16x16\n",
        "        )\n",
        "\n",
        "        self.cnv_block3 = nn.Sequential(\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, 3, padding=1, bias=False),  # Input -   7x7x16, Output -   7x7x32, RF - 24x24\n",
        "            nn.Dropout(DROP),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 32, 3, padding=1, bias=False),  # Input -   7x7x32, Output -   7x7x32, RF - 32x32\n",
        "            nn.Dropout(DROP),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.out_block = nn.Sequential(\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 32, 1, bias=False),             # Input -   7x7x32, Output -   7x7x32, RF - 32x32\n",
        "            nn.Dropout(DROP),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 10, 1),                         # Input -   7x7x32, Output -   7x7x10, RF - 32x32\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(7, 7),                           # Input -   7x7x10, Output -   1x1x10\n",
        "            nn.Flatten(),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnv_block1(x)\n",
        "        x = self.t_block1(x)\n",
        "        x = self.cnv_block2(x)\n",
        "        x = self.t_block2(x)\n",
        "        x = self.cnv_block3(x)\n",
        "        x = self.out_block(x)\n",
        "        return x\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56014001-288d-4d2f-c92c-da38859ba347"
      },
      "source": [
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              72\n",
            "           Dropout-2            [-1, 8, 28, 28]               0\n",
            "              ReLU-3            [-1, 8, 28, 28]               0\n",
            "       BatchNorm2d-4            [-1, 8, 28, 28]              16\n",
            "            Conv2d-5            [-1, 8, 28, 28]             576\n",
            "           Dropout-6            [-1, 8, 28, 28]               0\n",
            "              ReLU-7            [-1, 8, 28, 28]               0\n",
            "         MaxPool2d-8            [-1, 8, 14, 14]               0\n",
            "       BatchNorm2d-9            [-1, 8, 14, 14]              16\n",
            "           Conv2d-10           [-1, 16, 14, 14]           1,152\n",
            "          Dropout-11           [-1, 16, 14, 14]               0\n",
            "             ReLU-12           [-1, 16, 14, 14]               0\n",
            "      BatchNorm2d-13           [-1, 16, 14, 14]              32\n",
            "           Conv2d-14           [-1, 16, 14, 14]           2,304\n",
            "          Dropout-15           [-1, 16, 14, 14]               0\n",
            "             ReLU-16           [-1, 16, 14, 14]               0\n",
            "        MaxPool2d-17             [-1, 16, 7, 7]               0\n",
            "      BatchNorm2d-18             [-1, 16, 7, 7]              32\n",
            "           Conv2d-19             [-1, 32, 7, 7]           4,608\n",
            "          Dropout-20             [-1, 32, 7, 7]               0\n",
            "             ReLU-21             [-1, 32, 7, 7]               0\n",
            "      BatchNorm2d-22             [-1, 32, 7, 7]              64\n",
            "           Conv2d-23             [-1, 32, 7, 7]           9,216\n",
            "          Dropout-24             [-1, 32, 7, 7]               0\n",
            "             ReLU-25             [-1, 32, 7, 7]               0\n",
            "      BatchNorm2d-26             [-1, 32, 7, 7]              64\n",
            "           Conv2d-27             [-1, 32, 7, 7]           1,024\n",
            "          Dropout-28             [-1, 32, 7, 7]               0\n",
            "             ReLU-29             [-1, 32, 7, 7]               0\n",
            "      BatchNorm2d-30             [-1, 32, 7, 7]              64\n",
            "           Conv2d-31             [-1, 10, 7, 7]             330\n",
            "             ReLU-32             [-1, 10, 7, 7]               0\n",
            "        AvgPool2d-33             [-1, 10, 1, 1]               0\n",
            "          Flatten-34                   [-1, 10]               0\n",
            "       LogSoftmax-35                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 19,570\n",
            "Trainable params: 19,570\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.69\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 0.77\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35eccc87-b438-42b2-f3ee-c196a0191c24"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 95904628.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 38382665.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 27243685.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7785259.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'Train set: Average loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    return test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8285ddd2-7740-447a-c1ee-d202bb76f373"
      },
      "source": [
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, verbose=True)\n",
        "\n",
        "for epoch in range(0, 20):\n",
        "    print(\"Epoch {}: \".format(epoch + 1))\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test_loss = test(model, device, test_loader)\n",
        "    scheduler.step(test_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/938 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train set: Average loss=0.12361396104097366 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.1003, Accuracy: 9702/10000 (97.02%)\n",
            "\n",
            "Epoch 2: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.012935614213347435 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 44.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0819, Accuracy: 9748/10000 (97.48%)\n",
            "\n",
            "Epoch 3: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.16562581062316895 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 43.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0729, Accuracy: 9782/10000 (97.82%)\n",
            "\n",
            "Epoch 4: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.023357901722192764 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0505, Accuracy: 9835/10000 (98.35%)\n",
            "\n",
            "Epoch 5: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.0034697912633419037 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 41.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0644, Accuracy: 9801/10000 (98.01%)\n",
            "\n",
            "Epoch 6: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.04145248234272003 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0580, Accuracy: 9815/10000 (98.15%)\n",
            "\n",
            "Epoch 00006: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch 7: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.033638156950473785 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0321, Accuracy: 9897/10000 (98.97%)\n",
            "\n",
            "Epoch 8: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.001838184311054647 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 43.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0296, Accuracy: 9908/10000 (99.08%)\n",
            "\n",
            "Epoch 9: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.004358724690973759 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 44.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0333, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "Epoch 10: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.003821044461801648 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 43.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0313, Accuracy: 9900/10000 (99.00%)\n",
            "\n",
            "Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 11: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.01755845919251442 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0301, Accuracy: 9906/10000 (99.06%)\n",
            "\n",
            "Epoch 12: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.07338633388280869 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0313, Accuracy: 9903/10000 (99.03%)\n",
            "\n",
            "Epoch 00012: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch 13: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.0019218074157834053 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 41.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0301, Accuracy: 9904/10000 (99.04%)\n",
            "\n",
            "Epoch 14: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.011517610400915146 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0297, Accuracy: 9906/10000 (99.06%)\n",
            "\n",
            "Epoch 00014: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 15: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.03299829736351967 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 43.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0276, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "Epoch 16: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.022085009142756462 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 44.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0310, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "Epoch 17: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.01815761998295784 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 43.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0325, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "Epoch 00017: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch 18: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.010412867181003094 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0271, Accuracy: 9918/10000 (99.18%)\n",
            "\n",
            "Epoch 19: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.015343899838626385 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0296, Accuracy: 9908/10000 (99.08%)\n",
            "\n",
            "Epoch 20: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train set: Average loss=0.006899966858327389 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 41.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0330, Accuracy: 9896/10000 (98.96%)\n",
            "\n",
            "Epoch 00020: reducing learning rate of group 0 to 1.0000e-08.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
